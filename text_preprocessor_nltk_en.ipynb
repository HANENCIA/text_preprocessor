{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import html.parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Natural Language Toolkit(NLTK)을 이용하여 영어 전처리\n",
    "#\n",
    "# 1. Sample Data/Input Exmaple\n",
    "# input_data = ['There is no cow level.', 'Power Overwhelming.']\n",
    "# stem_opt = 'stem', 'lem', 'N' 중 1개 입력\n",
    "# input: output_data = make_preprocessed_voca_list(raw_list, stem_opt)\n",
    "#\n",
    "# 2. Output Example/Data\n",
    "# output_data: [['cow', 'level'], ['power', 'overwhelm']]\n",
    "\n",
    "def make_preprocessed_voca_list(raw_list, stem_opt):\n",
    "    preprocessed_voca_list = []\n",
    "    assert stem_opt in ['stem', 'lem', 'N']\n",
    "    stopword_list = set(stopwords.words('english'))\n",
    "\n",
    "    if stem_opt == 'stem':\n",
    "        stem = PorterStemmer()\n",
    "    elif stem_opt == 'lem':\n",
    "        stem = WordNetLemmatizer()\n",
    "\n",
    "    for line in raw_list:\n",
    "        if type(line).__name__ == 'float':\n",
    "            preprocessed_voca_list.append('')\n",
    "        else:\n",
    "            sentence_temp = html.unescape(line).lower()\n",
    "            sentence_temp = re.compile('[a-z]{3,}').findall(sentence_temp)\n",
    "            sentence_temp = list(filter(lambda x: x not in stopword_list, sentence_temp))\n",
    "            if stem_opt == 'stem':\n",
    "                sentence_temp = [stem.stem(w) for w in sentence_temp]\n",
    "            elif stem_opt == 'lem':\n",
    "                sentence_temp = [stem.lemmatize(w) for w in sentence_temp]\n",
    "            preprocessed_voca_list.append(sentence_temp)\n",
    "\n",
    "    return preprocessed_voca_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 전처리된 영어 단어 리스트에서 STOPWORDS 삭제\n",
    "#\n",
    "# 1. Sample Data/Input Exmaple\n",
    "# input_data = [['cow', 'level'], ['power', 'overwhelm']]\n",
    "# stopwords = ['cow']\n",
    "# output_data = remove_stopwords(input_data, stopwords)\n",
    "#\n",
    "# 2. Output Example/Data\n",
    "# output_data: [['level'], ['power', 'overwhelm']]\n",
    "\n",
    "\n",
    "def remove_stopwords(voca_list, stopword_list):\n",
    "    stopword_replaced_voca_list = []\n",
    "\n",
    "    for line in voca_list:\n",
    "        stopword_replaced_voca_list.append(list(filter(lambda x: x not in stopword_list, line)))\n",
    "\n",
    "    return stopword_replaced_voca_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 단어 리스트를 띄어쓰기를 기준으로 join\n",
    "#\n",
    "# 1. Sample Data/Input Exmaple\n",
    "# input_data = [['cow', 'level'], ['power', 'overwhelm']]\n",
    "# input: output_data = make_sentence_list_from_voca_list(input_data)\n",
    "#\n",
    "# 2. Output Example/Data\n",
    "# output_data: ['cow level', 'power overwhelm']\n",
    "\n",
    "def make_sentence_list_from_voca_list(voca_list):\n",
    "    sentence_list = []\n",
    "    for voca_line in voca_list:\n",
    "        sentence_list.append(\" \".join(voca_line))\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 단어 빈도순 출력\n",
    "#\n",
    "# 1. Sample Data/Input Exmaple\n",
    "# input_data = [['사과', '바나나', '사과'], ['딸기', '사과', '바나나', '수박']]\n",
    "# top_count = n (int, 상위 n위)\n",
    "# print_most_common_words(input_data, 4)\n",
    "#\n",
    "# 2. Output Example/Data\n",
    "# output_data: [('사과', 3), ('바나나', 2), ('딸기', 1), ('수박', 1)]\n",
    "# 주의: 동 순위가 있다면 앞에 있는 element 순서대로 끊어짐 (예: [('사과', 3), ('바나나', 2), ('딸기', 1)])\n",
    "\n",
    "def print_most_common_words(voca_list, top_count):\n",
    "    print(Counter(list(chain.from_iterable(voca_list))).most_common(top_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 단어 빈도 데이터 저장\n",
    "#\n",
    "# 1. Sample Data/Input Exmaple\n",
    "# input_data = [['사과', '바나나', '사과'], ['딸기', '사과', '바나나', '수박']]\n",
    "# top_count = n (int, 상위 n위, 저장 CSV 파일 경로)\n",
    "# print_most_common_words(input_data, 4)\n",
    "#\n",
    "# 2. Output Example/Data\n",
    "# output_data: CSV 파일\n",
    "# Column Name: WORD, COUNT\n",
    "# 주의: 동 순위가 있다면 앞에 있는 element 순서대로 끊어짐 (예: [('사과', 3), ('바나나', 2), ('딸기', 1)])\n",
    "\n",
    "def save_most_common_words(voca_list, top_count, output_path):\n",
    "    word_count_list = Counter(list(chain.from_iterable(voca_list))).most_common(top_count)\n",
    "    word_list = []\n",
    "    count_list = []\n",
    "    for idx in range(len(word_count_list)):\n",
    "        word_list.append(word_count_list[idx][0])\n",
    "        count_list.append(word_count_list[idx][1])\n",
    "    word_count_df = pd.DataFrame.from_records(zip(word_list, count_list), columns=['WORD', 'COUNT'])\n",
    "\n",
    "    word_count_df.to_csv(output_path, sep=',', index=False, encoding='utf-8-sig')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_path = 'data/sample_wos.csv'\n",
    "raw_list_name = 'ABSTRACT'\n",
    "\n",
    "raw_df = pd.read_csv(raw_path, sep=',', encoding='utf-8')\n",
    "raw_list = raw_df[raw_list_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_voca_list = make_preprocessed_voca_list(raw_list, 'stem')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stopwords_custom = ['use']\n",
    "stopword_replaced_voca_list = remove_stopwords(raw_voca_list, stopwords_custom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_most_common_words(stopword_replaced_voca_list, 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "common_words_path = 'data/sample_wos_common_word.csv'\n",
    "save_most_common_words(stopword_replaced_voca_list, 200, common_words_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_noun_sentence_list = make_sentence_list_from_voca_list(stopword_replaced_voca_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path = 'data/sample_wos_modified.csv'\n",
    "output_list_name = 'ABSTRACT_FIXED'\n",
    "\n",
    "\n",
    "raw_df[output_list_name] = raw_noun_sentence_list\n",
    "raw_df.to_csv(output_path, sep=',', index=False, encoding='utf-8-sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}